
        "## Exercises\n",
        "\n",
        "1. Assume that we have some data $x_1, \\ldots, x_n \\in \\mathbb{R}$. Our goal is to find a constant $b$ such that $\\sum_i (x_i - b)^2$ is minimized.\n",
        "    1. Find an analytic solution for the optimal value of $b$.\n",
        "    1. How does this problem and its solution relate to the normal distribution?\n",
        "    1. What if we change the loss from $\\sum_i (x_i - b)^2$ to $\\sum_i |x_i-b|$? Can you find the optimal solution for $b$?\n",
        "1. Prove that the affine functions that can be expressed by $\\mathbf{x}^\\top \\mathbf{w} + b$ are equivalent to linear functions on $(\\mathbf{x}, 1)$.\n",
        "1. Assume that you want to find quadratic functions of $\\mathbf{x}$, i.e., $f(\\mathbf{x}) = b + \\sum_i w_i x_i + \\sum_{j \\leq i} w_{ij} x_{i} x_{j}$. How would you formulate this in a deep network?\n",
        "1. Recall that one of the conditions for the linear regression problem to be solvable was that the design matrix $\\mathbf{X}^\\top \\mathbf{X}$ has full rank.\n",
        "    1. What happens if this is not the case?\n",
        "    1. How could you fix it? What happens if you add a small amount of coordinate-wise independent Gaussian noise to all entries of $\\mathbf{X}$?\n",
        "    1. What is the expected value of the design matrix $\\mathbf{X}^\\top \\mathbf{X}$ in this case?\n",
        "    1. What happens with stochastic gradient descent when $\\mathbf{X}^\\top \\mathbf{X}$ does not have full rank?\n",
        "1. Assume that the noise model governing the additive noise $\\epsilon$ is the exponential distribution. That is, $p(\\epsilon) = \\frac{1}{2} \\exp(-|\\epsilon|)$.\n",
        "    1. Write out the negative log-likelihood of the data under the model $-\\log P(\\mathbf y \\mid \\mathbf X)$.\n",
        "    1. Can you find a closed form solution?\n",
        "    1. Suggest a minibatch stochastic gradient descent algorithm to solve this problem. What could possibly go wrong (hint: what happens near the stationary point as we keep on updating the parameters)? Can you fix this?\n",
        "1. Assume that we want to design a neural network with two layers by composing two linear layers. That is, the output of the first layer becomes the input of the second layer. Why would such a naive composition not work?\n",
        "1. What happens if you want to use regression for realistic price estimation of houses or stock prices?\n",
        "    1. Show that the additive Gaussian noise assumption is not appropriate. Hint: can we have negative prices? What about fluctuations?\n",
        "    1. Why would regression to the logarithm of the price be much better, i.e., $y = \\log \\textrm{price}$?\n",
        "    1. What do you need to worry about when dealing with pennystock, i.e., stock with very low prices? Hint: can you trade at all possible prices? Why is this a bigger problem for cheap stock? For more information review the celebrated Black--Scholes model for option pricing :cite:`Black.Scholes.1973`.\n",
        "1. Suppose we want to use regression to estimate the *number* of apples sold in a grocery store.\n",
        "    1. What are the problems with a Gaussian additive noise model? Hint: you are selling apples, not oil.\n",
        "    1. The [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) captures distributions over counts. It is given by $p(k \\mid \\lambda) = \\lambda^k e^{-\\lambda}/k!$. Here $\\lambda$ is the rate function and $k$ is the number of events you see. Prove that $\\lambda$ is the expected value of counts $k$.\n",
        "    1. Design a loss function associated with the Poisson distribution.\n",
        "    1. Design a loss function for estimating $\\log \\lambda$ instead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resolução dos exercícios - Miguel Pedrosa do Carmo Nonato**"
      ],
      "metadata": {
        "id": "mIFvX6rYxTKL"
      },
      "id": "mIFvX6rYxTKL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instalando as bibliotecas necessárias."
      ],
      "metadata": {
        "id": "tYVgQJP8xYRf"
      },
      "id": "tYVgQJP8xYRf"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfN2OJRWxYbo",
        "outputId": "ff0903ea-6335-4ffe-81f0-7285242942c0"
      },
      "id": "YfN2OJRWxYbo",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importando as bibliotecas principais\n"
      ],
      "metadata": {
        "id": "55ywcDqRzZDX"
      },
      "id": "55ywcDqRzZDX"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes, load_iris\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "FwSvRzMPzZXA"
      },
      "id": "FwSvRzMPzZXA",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Funções auxiliares"
      ],
      "metadata": {
        "id": "nERIg61bzskK"
      },
      "id": "nERIg61bzskK"
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliar_classificacao(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    erro = 1 - acc\n",
        "    print(f\"Acurácia: {acc:.4f}\")\n",
        "    print(f\"Taxa de erro: {erro:.4f}\")\n",
        "\n",
        "def avaliar_regressao(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    print(f\"MSE (Erro Quadrático Médio): {mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "GoFCSS5rzstN"
      },
      "id": "GoFCSS5rzstN",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Naive Bayes (Classificação)"
      ],
      "metadata": {
        "id": "lt_8ww0n1Scf"
      },
      "id": "lt_8ww0n1Scf"
    },
    {
      "cell_type": "code",
      "source": [
        "dados = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dados.data, dados.target, test_size=0.3, random_state=42)\n",
        "\n",
        "modelo_nb = GaussianNB()\n",
        "modelo_nb.fit(X_train, y_train)\n",
        "y_pred_nb = modelo_nb.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes:\")\n",
        "avaliar_classificacao(y_test, y_pred_nb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j60HpWS-1daX",
        "outputId": "60944b5e-732d-4e79-defe-d295052c39da"
      },
      "id": "j60HpWS-1daX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes:\n",
            "Acurácia: 0.9415\n",
            "Taxa de erro: 0.0585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Regressão Linear (Regressão)"
      ],
      "metadata": {
        "id": "8uF1KSEO1geI"
      },
      "id": "8uF1KSEO1geI"
    },
    {
      "cell_type": "code",
      "source": [
        "dados = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dados.data, dados.target, test_size=0.3, random_state=42)\n",
        "\n",
        "modelo_rl = LinearRegression()\n",
        "modelo_rl.fit(X_train, y_train)\n",
        "y_pred_rl = modelo_rl.predict(X_test)\n",
        "\n",
        "print(\"Regressão Linear:\")\n",
        "avaliar_regressao(y_test, y_pred_rl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPnc4-w81lH1",
        "outputId": "85c0217b-3c46-4a2b-b86f-eba06516b105"
      },
      "id": "JPnc4-w81lH1",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regressão Linear:\n",
            "MSE (Erro Quadrático Médio): 2821.7510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Regressão Logística (Classificação)"
      ],
      "metadata": {
        "id": "VHDlKtSw1oHN"
      },
      "id": "VHDlKtSw1oHN"
    },
    {
      "cell_type": "code",
      "source": [
        "dados = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dados.data, dados.target, test_size=0.3, random_state=42)\n",
        "\n",
        "modelo_log = LogisticRegression(max_iter=10000)\n",
        "modelo_log.fit(X_train, y_train)\n",
        "y_pred_log = modelo_log.predict(X_test)\n",
        "\n",
        "print(\"Regressão Logística:\")\n",
        "avaliar_classificacao(y_test, y_pred_log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP-JHrPk1pVu",
        "outputId": "e67a0a5c-7c5f-494b-a5d7-8cdd0efd555c"
      },
      "id": "TP-JHrPk1pVu",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regressão Logística:\n",
            "Acurácia: 0.9766\n",
            "Taxa de erro: 0.0234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Perceptron (Classificação)"
      ],
      "metadata": {
        "id": "gOR4KwmS1pJk"
      },
      "id": "gOR4KwmS1pJk"
    },
    {
      "cell_type": "code",
      "source": [
        "dados = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dados.data, dados.target, test_size=0.3, random_state=42)\n",
        "\n",
        "modelo_perc = Perceptron(max_iter=1000, tol=1e-3)\n",
        "modelo_perc.fit(X_train, y_train)\n",
        "y_pred_perc = modelo_perc.predict(X_test)\n",
        "\n",
        "print(\"Perceptron:\")\n",
        "avaliar_classificacao(y_test, y_pred_perc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmB0s5P1wWB",
        "outputId": "933138ee-b71e-4829-a06d-3c9144d1d4bc"
      },
      "id": "vOmB0s5P1wWB",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron:\n",
            "Acurácia: 0.8222\n",
            "Taxa de erro: 0.1778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. k-Fold Cross Validation com Regressão Linear"
      ],
      "metadata": {
        "id": "tCWkGOyW1zD-"
      },
      "id": "tCWkGOyW1zD-"
    },
    {
      "cell_type": "code",
      "source": [
        "dados = load_diabetes()\n",
        "modelo = LinearRegression()\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(modelo, dados.data, dados.target, cv=kf, scoring='neg_mean_squared_error')\n",
        "print(\"k-Fold Cross Validation com Regressão Linear:\")\n",
        "print(\"MSE médio:\", -scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OovXXxCy12by",
        "outputId": "afedade6-f602-4ab2-f1fb-da097db1eb71"
      },
      "id": "OovXXxCy12by",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-Fold Cross Validation com Regressão Linear:\n",
            "MSE médio: 3015.381694287271\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
